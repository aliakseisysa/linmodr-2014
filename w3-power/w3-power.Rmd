---
title       : Анализ мощности
subtitle    : Линейные модели, осень 2014
author      : Марина Варфоломеева
job         : Каф. Зоологии беспозвоночных, СПбГУ
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : idea      # 
widgets     : [mathjax]            # {mathjax, quiz, bootstrap}
mode        : standalone # {selfcontained, standalone, draft}
---

```{r setup, include = FALSE, cache = FALSE}
#----------------------------------------------------------------
# RUN THE FRAGMENT BETWEEN LINES BEFORE COMPILING MARKDOWN
# to configure markdown parsing
options(markdown.extensions = c("no_intra_emphasis", "tables", "fenced_code", "autolink", "strikethrough", "lax_spacing", "space_headers", "latex_math"))
#--------------------------------------------------------------
# output options
options(width = 70, scipen = 6, digits = 3) 
# to render cyrillics in plots use cairo pdf
options(device = function(file, width = 7, height = 7, ...) {
  cairo_pdf(tempfile(), width = width, height = height, ...)
  })
library(knitr)
# chunk default options
opts_chunk$set(fig.align='center', fig.width = 10, fig.height = 6, cache = FALSE, comment="#") 

# this allows for code formatting inline
knit_hooks$set(inline = function(x) {
   if (is.numeric(x)) return(knitr:::format_sci(x, 'latex'))
   x = as.character(x)
   h = knitr:::hilight_source(x, 'latex', list(prompt = FALSE, 
                                               size='normalsize', 
                                               highlight = FALSE))
   h = gsub("([_#$%&])", "\\\\\\1", h)
   h = gsub('(["\'])', '\\1{}', h)
   gsub('^\\\\begin\\{alltt\\}\\s*|\\\\end\\{alltt\\}\\s*$', '', h)})
```

## Экономим силы с помощью анализа мощности

- Статистические ошибки при проверке гипотез
- Мощность статистического теста
- *A priori* анализ мощности, оценка величины эффекта
- *Post hoc* анализ мощности
- Как влиять на мощность тестов

### Вы сможете

- дать определение ошибок I и II рода, мощности теста, и изобразить их вероятности на графике
- оценивать величину эффекта и необходимый объем выборки по данным пилотного исследования (a priori анализ мощности)
- загружать данные из .csv в R
- строить боксплоты с помощью `ggplot2`, раскрашивать их, менять темы оформления
- сравнивать средние значения при помощи t-критерия, интерпретировать и описывать результаты
- расчитывать фактическую мощность теста (post hoc анализ мощности)

--- .segue

# Статистические ошибки при проверке гипотез

---

## Типы ошибок при проверке гипотез

```{r, echo=FALSE}
df <- data.frame (v1 = c("<strong>Ошибка I рода</strong><br />Ложно-положительный результат", 
                   "Верно<br />Отрицательный результат"),
            v2 = c("Верно<br />Положительный результат",
                   "<strong>Ошибка II рода</strong><br />Ложно-отрицательный результат"),
            stringsAsFactors = F)
rownames(df) <- c("Отклонить<br />H0", "Сохранить<br />H0")
colnames(df) <- c("H0 == TRUE", "H0 == FALSE")
```

```{r, ptable, echo=FALSE, results='asis'}
kable(df, format = "markdown")
```


```{r power_data, echo = FALSE, cache = TRUE}
# Power plot using ggplot2
# reworked after 
# http://rpsychologist.com/creating-a-typical-textbook-illustration-of-statistical-power-using-either-ggplot-or-base-graphics/

library(ggplot2)
library(gridExtra) # to rescale legend

# theme_bw without axes and with larger legend
theme_bw_noxy <- function (base_size = 12, base_family = "") 
{
  require(ggplot2)
  theme_bw(base_size = base_size, base_family = base_family) %+replace% 
    theme(panel.border = element_blank(), axis.line = element_line(colour = "black"), 
          panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
          axis.line = element_blank(), axis.text = element_blank(), 
          axis.ticks = element_blank(), axis.title = element_blank(),
          legend.key = element_blank(),
          legend.key.size = unit(3, "lines"), 
          legend.text = element_text(size = 24, hjust = 0.5))
}

generate_power_data <- function(m1 = 0, sd1 = 7, m2 = 3.5, sd2 = 7, alpha = 0.05, h.type = "equal"){
  # set length of tails
  min1 <- m1-sd1*4
  max1 <- m1+sd1*4
  min2 <- m2-sd2*4
  max2 <- m2+sd2*4
  # create a sequence for x axis including z.crit
  x <- seq(min(min1,min2), max(max1, max2), .01)
  # compute critical value
  
  switch(h.type,
         greater={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },
         less={
           z.crit <- qnorm(1-alpha, m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         },                            
         equal={
           z.crit <- qnorm(1-(alpha/2), m1, sd1)
           z.critm <- m1 - abs(m1 - z.crit)
         }
  )
  x[length(x)+1] <- z.crit
  x[length(x)+1] <- z.critm
  x <- sort(x)
  
  # generate normal distributions
  y1 <- dnorm(x, m1, sd1)
  y2 <- dnorm(x, m2, sd2)
  # combine to data frame
  df1 <- data.frame(x = x, y = y1)
  df2 <- data.frame(x = x, y = y2)
  # compute intervals for polygons
  outside.l <- x <= z.critm
  inside <- (x >= z.critm) & (x <= z.crit)
  outside.r <- x >= z.crit
  
  switch(h.type,
         greater={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
           } else {
             alph <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
           }
           alph$y[alph$x == z.crit] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.l | inside], y = y2[outside.l | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0  
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd$y[pwrd$x == z.crit] <- 0    
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))
         },
         less={
           # Alpha polygon
           if(m1 < m2){
             alph <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else{
             alph <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l]))
           }
           alph$y[alph$x == z.critm] <- 0
           # Beta polygon one-tailed
           bet <- data.frame(x = x[outside.r | inside], y = y2[outside.r | inside])
           bet$y[bet$x == z.crit] <- 0
           bet$y[bet$x == z.critm] <- 0
           # power polygon; 1-beta, one-tailed
           pwrd <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd$y[pwrd$x == z.critm] <- 0
           alph$id <- 3
           bet$id <- 2
           pwrd$id <- 1
           alph$obj <- 3
           bet$obj <- 2
           pwrd$obj <- 1
           # combine data frames
           poly <- rbind(alph, bet, pwrd)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))  
         },
         equal={
           # alph polygon
           if(m1 < m2){
             alph.r <- data.frame(x = x[outside.r], y = pmin(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmax(y1[outside.l], y2[outside.l]))
           } else {
             alph.r <- data.frame(x = x[outside.r], y = pmax(y1[outside.r], y2[outside.r]))
             alph.l <- data.frame(x = x[outside.l], y = pmin(y1[outside.l], y2[outside.l])) 
           }
           alph.r$y[alph.r$x == z.crit] <- 0
           alph.l$y[alph.l$x == z.critm] <- 0
           # beta polygon, two-tailed
           bet <- data.frame(x = x[inside], y = y2[inside])
           bet$y[bet$x == z.crit] <- 0 
           bet$y[bet$x == z.critm] <- 0 
           # two power polygons, two-tailed
           pwrd.l <- data.frame(x = x[outside.l], y = y2[outside.l])
           pwrd.l$y[pwrd.l$x == z.critm] <- 0
           pwrd.r <-data.frame(x = x[outside.r], y = y2[outside.r])
           pwrd.r$y[pwrd.r$x == z.crit] <- 0
           alph.l$id <- 3
           alph.l$obj <- 5
           alph.r$id <- 3
           alph.r$obj <- 4
           bet$id <- 2
           bet$obj <-3
           pwrd.l$id <- 1
           pwrd.l$obj <- 2
           pwrd.r$id <- 1
           pwrd.r$obj <- 1
           # combine data frames
           poly <- rbind(alph.l, alph.r, bet, pwrd.l, pwrd.r)
           poly$id <- factor(poly$id,  labels = c("power","beta","alpha"))  
           poly$obj <- factor(poly$obj,  labels = c("powerr","powerl", "beta", "alphar", "alphal"))  
         }
  )
  return(list(df1 = df1, df2 = df2, poly = poly, m1 = m1, m2 = m2, h.type = h.type, z.crit = z.crit, z.critm = z.critm))
}

pwr_plot <- function(pwrd, alph = TRUE, bet = TRUE, power = TRUE, ann = TRUE){
  require(ggplot2)
  # initialise filter for the data
  filter <- vector(length = length(pwrd$poly$id))
  # possible values for the scale
  category <- vector()
  lbls <- vector()
  if(alph){
    filter <- pwrd$poly$id == "alpha"
    category <- c(category, "alpha")
    lbls <- c(lbls, bquote(alpha))
  }
  if(bet){
    filter <- filter | pwrd$poly$id == "beta"
    category <- c(category, "beta")
    lbls <- c(lbls, bquote(beta))
  }
  if(power){
    filter <- filter | pwrd$poly$id == "power"
    category <- c(category, "power")
    lbls <- c(lbls, bquote(1 - beta))
  }
  # define colours by type of polygon
  cols <- c("alpha" = "red", "beta" = "blue", "power" = "green")
  if(any(alph, bet, power)){
  p <- ggplot() +
    geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
    geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
    geom_polygon(data = pwrd$poly[filter, ], aes(x, y, fill = id, group = obj), alpha = 0.3) +
    scale_linetype_discrete(name = "Гипотезы") +
    scale_fill_manual(values = cols, limits = category, name = "Вероятности", labels = lbls)
  } else {
    p <- ggplot() +
      geom_line(data = pwrd$df1, aes(x, y, linetype = "H0", group = NULL, fill = NULL)) +
      geom_line(data = pwrd$df2, aes(x, y, linetype = "Ha", group = NULL, fill = NULL)) +
      scale_linetype_discrete(name = "Гипотезы")    
  }
  return(p)
}

dat <- generate_power_data(m1 = 0, m2 = 5, sd1 = 10, sd2 = 10, h.type = "equal")
```

### Вероятности гипотез

```{r power_curves, echo = FALSE, fig.height=3.5}
pwr_plot(pwrd = dat, alph = F, bet = F, power = F) + 
  guides(linetype = guide_legend(title = NULL)) + 
  theme_bw_noxy(base_size = 28)
```

---

## Типы ошибок при проверке гипотез

```{r, ptable, echo=FALSE, results='asis'}
```


### Ошибки I рода

```{r power_alpha, echo = FALSE, fig.height=3.5}
pwr_plot(pwrd = dat, alph = T, bet = F, power = F) + 
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) + 
  theme_bw_noxy(base_size = 28)
```

---


## Типы ошибок при проверке гипотез

```{r, ptable, echo=FALSE, results='asis'}
```


### Ошибки II рода

```{r power_beta, echo = FALSE, fig.height=3.5}
pwr_plot(pwrd = dat, alph = T, bet = T, power = F) + 
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) + 
  theme_bw_noxy(base_size = 28)
```

---


## Типы ошибок при проверке гипотез

```{r, ptable, echo=FALSE, results='asis'}
```


### Мощность теста - способность выявлять различия $Power = 1 - \beta$

```{r echo = FALSE, fig.height=3.5, fig.width=10.1}
pwr_plot(pwrd = dat, alph = T, bet = T, power = T) + 
  guides(fill = guide_legend(title = NULL), linetype = guide_legend(title = NULL)) + 
  theme_bw_noxy(base_size = 28)
```


--- &twocol w1:40% w2:60%

## Анализ мощности


*** {name: left}

<center>*A priori*</center>

- какой нужен объем выборки, чтобы найти различия с разумной долей уверенности?
- различия какой величины мы можем найти, если известен объем выборки?

*** {name: right}

<center>*Post hoc*</center>

- смогли бы мы найти различия при помощи нашего эксперимента ($\alpha$, $n$), если бы величина эффекта была $X$?

--- .segue

# A priory анализ мощности 


--- .sub-section

## Пример: Заповедник спасает халиотисов *

Лов халиотисов (коммерческий и любительский) запретили, организовав заповедник.

Стало ли больше моллюсков через несколько лет? (Keough, King, 1991)

### Для a priori анализа нужно знать

- тест - $t$-критерий
- уровень значимости - $alpha = 0.05$
- желаемая мощность теста - 80%
- ожидаемая величина эффекта - ?

<div class = "footnote">* - Данные из Quinn, Keough, 2002, Box 9-5, Fig 9-7</div>

--- &twocol

## Как оценить ожидаемую величину эффекта?
<div class="floatright" style="float:right; margin: 0 0 10px 10px; padding: 10px; ">
<img src="./assets/img/Jacob Cohen.jpg" alt="Яков Коэн"  style="float:right; margin:0 5px 0 0;"/>
<p style="margin-top: 0; margin-bottom: 0; text-align: center;">Яков Коэн</p>
</div>

$d$ Коэна (Cohen's d) 

$$d = \frac{\bar \mu_1 - \bar \mu_2}{\sigma}$$

- Пилотные исследования
- Литература
- Общебиологические знания
- Технические требования

### Как оценить стандартное отклонение для расчета величины эффекта?

*** =left

- как среднеквадратичное стандартное отклонение  
($d$ Коэна)

\[d = \frac{|\bar x_1 - \bar x_2|} {\sqrt{\frac {s_1^2 + s_2^2 } {2} }}\]

*** =right

- как обобщенное стандартное отклонение  
($g$ Хеджа)

\[g = \frac{|\bar x _1 - \bar x _2|} {\sqrt{\frac {(n _1 - 1)s_1^2 + (n _2 - 1)s_2^2 }  {n _1 + n _2 - 2} } }\]

---

## Величина эффекта из общих соображений

Яков Коэн (1982)

сильные, умеренные и слабые эффекты
```{r }
library(pwr)
cohen.ES(test = "t", size = "large")
```

--- .prompt

## Задача: 


Рассчитайте величину умеренных и слабых эффектов для t-критерия

```{r eval = FALSE}
    library()
    cohen.ES()
```

<small>Подсказка: обозначения можно посмотреть в файлах справки</small>

```{r eval = FALSE}
    help(cohen.ES)
    ?cohen.ES
    cohen.ES # курсор на слове, нажать F1
```

---

## Величина эффекта из пилотных данных

$$d = \frac{\bar \mu_1 - \bar \mu_2}{\sigma}$$

### ${\sigma}$ - cтандартное отклонение плотности халиотисов:
- Плотность крупных халиотисов на $50 м^2$ была $\bar x = 47.5$, $SD = 27.7$


### ${\bar \mu_1 - \bar \mu_2}$ - cредний вылов халиотисов в год:
- Масса выловленных коммерческим способом + данные о размерах -> численность -> плотность -> коммерческий лов  = 11.6 экз. $м^{-2}$
- -> общий вылов = 23.2 экз. $м^{-2}$ (если любительский и коммерческий лов равны)

---

## Величина эффекта из пилотных данных

$$d = \frac{\bar \mu_1 - \bar \mu_2}{\sigma}$$

### ${\sigma}$ - cтандартное отклонение плотности халиотисов:
- Плотность крупных халиотисов на $50 м^2$ была $\bar x = 47.5$, $SD = 27.7$


### ${\bar \mu_1 - \bar \mu_2}$ - cредний вылов халиотисов в год:
- Масса выловленных коммерческим способом + данные о размерах -> численность -> плотность -> коммерческий лов  = 11.6 экз. $м^{-2}$
- -> общий вылов = 23.2 экз. $м^{-2}$ (если любительский и коммерческий лов равны)

```{r}
alpha <- 0.05
power <- 0.80
sigma <- 27.7 # варьирование плотности халиотисов
diff <- 23.2 # ожидаемые различия плотности халиотисов
(effect <- diff/sigma) # величина эффекта
```

---

## Считаем объем выборки

### Функции для анализа мощности t-критерия

- при одинаковых объемах групп `pwr.t.test()`
- при разных объемах групп `pwr.t2n.test()`

```{r}
pwr.t.test(n = NULL, d = effect, power = power, sig.level = alpha, 
           type = "two.sample", alternative = "two.sided")
```

>- Чтобы с вероятностью 0.8 выявить различия плотности халиотисов в местах, где лов разрешен и запрещен, нужно обследовать __по 24 места каждого типа__, если мы верно оценили величину эффекта.

--- .prompt

## Задача:

Рассчитайте сколько нужно обследовать мест, чтобы обнаружить слабый эффект  
с вероятностью 0.8, при уровне значимости 0.01

```{r eval = FALSE}
    cohen.ES()
    pwr.t.test()
```

---

## Решение

```{r}
cohen.ES(test = "t", size = "small")
pwr.t.test(n = NULL, d = 0.2, power = 0.8, sig.level = 0.01, 
           type = "two.sample", alternative = "two.sided")
```

--- &twocol

## Пример: Улитки*

Улитки <em>Patelloida mimula</em> на устрицах <em>Saccostrea glomerata</em>? Minchinton, Ross, 1999

Сколько нужно проб, чтобы показать, что плотность улиток различается между сайтами?

<div class = "footnote">* - Данные из Quinn, Keough, 2002, Box 9-5, Fig 9-7.</div>

*** =left

### Читаем данные из файла

Не забудте войти в вашу директорию для матметодов

Читаем из `.csv`

```{r, message = FALSE}
minch <- read.table("./data/minch.csv", 
                    header = TRUE, sep = "\t")
```

Или читаем из `.xls`

```{r}
library(XLConnect)
minch <- readWorksheetFromFile("./data/minch.xls", 
                               sheet = 1)
```


>- Кто помнит, как посмотреть, что внутри переменной `minch`?

*** =right

<div class="floatright" style="float:right; margin: 0 0 10px 10px; padding: 10px; ">
<img src="./assets/img/oysters.jpg" alt="Устрицы"  style="display:block;margin:0 auto 0 auto;"/>
<small>Фото: http://users.monash.edu.au/~murray/stats/BIO4200/Eworksheets/images/oysters.jpg</small>
</div>

---

## Просмотреть, что внутри переменной `minch` можно так:

```{r, eval=FALSE}
# Структура данных
str(minch)
# Первые несколько строк
head(minch, 2)
# Первые три значения переменной zone
minch$zone[1:3] 
# 2-3 строки и 3, 5, 7 столбцы
minch[2:3, c(1, 3, 5)] 
# Полностью столбцы site и zone
minch[, c("site", "zone")]
```

---

## Боксплот числа улиток в двух сайтах

Геом `geom_boxplot`

```{r, echo=FALSE}
theme_set(theme_grey(base_size = 18))
```

```{r}
library(ggplot2)
gglimp <- ggplot(data = minch, aes(x = site, y = limpt100)) 
gglimp + geom_boxplot()
```

---

## Раскрашиваем график

эстетика `fill`

```{r, fig.height = 5}
gglimp + geom_boxplot(aes(fill = site))
```

--- .prompt

## Задание: Поэкспериментируйте с эстетиками

Чем отличаются результаты применения эстетик `fill` и `colour`?

```
ggplot()
aes()
geom_boxplot()
```

---

## Решение:

```
gglimp + geom_boxplot(aes(colour = site))
gglimp + geom_boxplot(aes(fill = zone))
gglimp + geom_boxplot(aes(colour = zone))
```

```{r, echo=FALSE, fig.width=12}
grid.arrange(gglimp + geom_boxplot(aes(colour = site)),
gglimp + geom_boxplot(aes(fill = zone)),
gglimp + geom_boxplot(aes(colour = zone)),
ncol = 3)
```


---

## Не нравится тема? Можно привинтить другую!

Можно прибавить к графику `theme_bw()`, `theme_classic()`, `theme_grey()`, `theme_minimal()`, `theme_light()`

```{r, eval=FALSE}
gglimp + geom_boxplot(aes(fill = site)) + theme_classic()
```

Можно установить для всех последующих графиков `theme_set()`

```{r, eval=FALSE}
theme_set(theme_bw()) # тема до конца сеанса
gglimp + geom_boxplot(aes(fill = site))
```
```{r, echo=FALSE, fig.height=5}
grid.arrange(gglimp + geom_boxplot(aes(fill = site)) + theme_classic(base_size = 18),
             gglimp + geom_boxplot(aes(fill = site)) + theme_bw(base_size = 18),
             nrow = 1)
theme_set(theme_bw(base_size = 18)) #
```

--- .segue

# A priory анализ мощности по данным пилотного исследования

---  &twocol

## Пилотное исследование 

Какой объем выборки нужен, чтобы доказать что численность улиток различается между сайтами?

*** =left

### Величина эффекта по исходным данным


```{r}
library(effsize)
effect <- cohen.d(minch$limpt100, minch$site)
effect
```

>- как добыть из переменной effect значение величины эффекта?

*** =right

```{r, echo=FALSE, fig.width=5}
gglimp + geom_boxplot(aes(fill = site))
```


---

## Обращении к переменным по имени - `$`

### Как называется в структуре объекта элемент, где записана величина эффекта?

```{r}
str(effect) # effect$estimate
# Для pwr.t.test() эффект должен быть положительным, поэтому вычислим модуль
effect <- abs(effect$estimate) 
```

>- Очень слабый эффект `r effect`

--- .prompt

## Задача:

Рассчитайте объем выборки, чтобы показать различия плотности улиток между сайтами с вероятностью 0.8?

```{r eval = FALSE}
pwr.t.test()
```

---

## Решение

```{r}
pwr.t.test(n = NULL, d = effect, power = 0.8, sig.level = 0.05, 
           type = "two.sample", alternative = "two.sided")
```
```{r, echo=FALSE}
sz <- pwr.t.test(n = NULL, d = effect, power = 0.8, sig.level = 0.05, 
           type = "two.sample", alternative = "two.sided")
```

>- Площадок должно быть __`r ceiling(sz$n)` с каждого сайта__, чтобы с вероятностью 0.8 обнаружить различия плотности улиток между сайтами.

--- .segue

# Post hoc анализ мощности 

--- &twocol

## На самом деле различия действительно не были найдены

<div class = "footnote">* - Данные из Quinn, Keough, 2002, Box 7-1, Fig 7-4</div>

*** =left

```{r}
t.test(limpt100 ~ site, data = minch, 
       var.equal = FALSE)
```

>- Достоверных различий плотности улиток между локациями не обнаружено (t-критерий)

*** =right

```{r, fig.width = 5, fig.align='right', echo=FALSE}
gglimp + geom_boxplot(aes(fill = site))
```

--- &twocol w1:40% w2:60%

## Post hoc анализ - когда различий не нашли

Какова была реальная величина эффекта?

Хватило ли нам мощности, чтобы выявлять такие незначительные различия?

*** =left

### Для post hoc анализа нужно знать

- тест ($H _0$ отвергнута!) — t-критерий
- уровень значимости — α = 0.05
- фактический объем выборки — 20
- фактическая величина эффекта — ?
- реальная мощность теста - ?

*** =right

```{r}
effect_real <- cohen.d(minch$limpt100, minch$site)
effect_real <- abs(effect_real$estimate)
pwr.t.test(n = 20, d = effect_real, 
           power = NULL, sig.level = 0.05, 
           type = "two.sample", 
           alternative = "two.sided")
```

--- .segue

# Как влиять на мощность теста?

---

## Чем больше объем выборки—тем больше мощность

```{r pwr_vs_n, echo = FALSE, cache = TRUE, warning = FALSE, message = FALSE, fig.height=7.5, fig.width=12}
# Plots of power vs. sample size etc.
# Modified after http://imdevsoftware.wordpress.com/2013/01/17/255/

# Need pwr, reshape2, ggplot2 packages
gen_pwr_vs_n <- function(d = c(0.2, 0.5, 0.8), a = c(0.05, 0.01), n = 150){
  if(!require(pwr)){install.packages("pwr");library("pwr")}
  # t-TEST
  #---------------------------------
  n <- 1:n
  t.test.power.effect<-
    as.data.frame(do.call("cbind", lapply(1:length(d),function(i){
    sapply(1:length(a),function(k){
      sapply(1:length(n), function(j){
        #       paste(d[i], n[j], a[k])
        power.t.test(n = n[j],d = d[i],sig.level = a[k],power = NULL,
                     type = "two.sample")$power
      })
    })
  })))
  t.test.power.effect[is.na(t.test.power.effect)]<-0 # some powers couldn't be calculated, set these to zero
  # melt the data
  if(!require(reshape2)){install.packages("reshape2");library("reshape2")}
  measured <- length(d)*length(a)
  t.test.power.effect <- melt(t.test.power.effect, measure.vars = 1:measured)
  # fill the levels of n, a, and d
  nms <- expand.grid(size = n, sig.level = a, effect = d)
  t.test.power.effect <- cbind(t.test.power.effect, nms)
  # do-not need variable column
  t.test.power.effect <- t.test.power.effect[, -1]
  return(t.test.power.effect)
}

dat <-gen_pwr_vs_n(n = 150)
# factors
dat$sig.level <- factor(dat$sig.level, levels = c(0.01, 0.05), 
                        labels = c("p = 0.01", "p = 0.05"))
dat$effect <- factor(dat$effect, levels = c(0.2, 0.3, 0.5, 0.8), 
                     labels = c("d = 0.2", "d = 0.3", "d = 0.5", "d = 0.8"))

# Power increases as the sample size increases
# plot power vs n at d = 0.5, p = 0.01
pwr.size <- 
  ggplot(data = dat[(dat$effect == "d = 0.5" & dat$sig.level == "p = 0.05"), ], 
         aes(x = size, y = value, color = sig.level)) + 
  geom_line(size = 1.5) + 
  scale_colour_discrete(name = "Уровень\nзначимости") +
  labs(x = "Объем выборки", y = "Мощность") +
  ggtitle("t-тест, d = 0.5") + 
  theme_minimal(base_size = 22) +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr.size
```

---

## Чем больше уровень значимости—тем больше мощность

```{r cache = TRUE, dependson='pwr_vs_n', echo = FALSE, warning = FALSE, fig.height=7.5, fig.width=12}
# Power increases as the signifficance level increases
#   plot power vs n at d = 0.5, add linetype = sig.level (p = 0.01, p = 0.05)
pwr_size_apha <- ggplot(data = dat[dat$effect == "d = 0.5", ], 
                        aes(x = size, y = value, color = sig.level)) + 
  geom_line(size = 1.5) + 
  scale_colour_discrete(name = "Уровень\nзначимости", 
                        limits = c("p = 0.05", "p = 0.01")) +
  labs(x = "Объем выборки", y = "Мощность") +
  ggtitle("t-тест, d = 0.5") + 
  theme_minimal(base_size = 22) +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr_size_apha
```

---

## Чем больше величина различий—тем больше мощность

```{r cache = TRUE, dependson='pwr_vs_n', echo = FALSE, warning = FALSE, fig.height=7.5, fig.width=12}
# Power increases as effect size increases
#   plot power vs n at
# add linetype = sig.level (p = 0.01, p = 0.05)
# add facets for d = 0.2, d = 0.5, d = 0.8
pwr_size_alpha_d <- ggplot(data = dat, aes(x = size, y = value, color = sig.level)) + 
    geom_line(size = 1.5) + facet_wrap(~effect) +
  scale_colour_discrete(name = "Уровень\nзначимости", 
                        limits = c("p = 0.05", "p = 0.01")) +
  labs(x = "Объем выборки", y = "Мощность") +
  ggtitle("t-тест") + 
  theme_minimal(base_size = 24) +
  theme(legend.key = element_blank(),
        axis.line = element_line(colour = "black"))
pwr_size_alpha_d
```

--- .prompt

## Задание:

Какие из факторов, влияющих на мощность теста, мы __не можем__ контролировать?

> - Мы не можем контролировать внешние факторы
    - величину эффекта ($ES$)
    - фоновую изменчивость ($\sigma^2$)

Каким образом можно повлиять на мощность теста?

> - Мощность теста можно регулировать, если
    - изменить число повторностей
    - выбрать другой уровень значимости ($\alpha$)
    - определиться, какие эффекты действительно важны ($ES$)

---

## Take home messages

- Контролируем статистические ошибки:
    - чтобы не находить несуществующих эффектов, фиксируем уровень значимости
    - чтобы не пропустить значимое, рассчитываем величину эффекта, объем выборки и мощность теста
    - когда не обнаружили достоверных эффектов, оцениваем величину эффекта и мощность теста

- Способность выявлять различия зависит 
    - от объема выборки, 
    - от уровня значимости
    - от величины эффекта

---

# Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 164-170
- Open Intro to Statistics: [4.6 Sample Size and Power](http://www.openintro.org/stat/down/oiStat2_04.pdf), pp. 193-197  
- Sokal, Rohlf, 1995, pp. 167-169.  
- Zar, 1999, p. 83.
- [R Data Analysis Examples - Power Analysis for Two-group Independent sample t-test. UCLA: Statistical Consulting Group.](http://www.ats.ucla.edu/stat/r/dae/t_test_power2.htm)
- [R Data Analysis Examples - Power Analysis for One-sample t-test.  UCLA: Statistical Consulting Group.](http://www.ats.ucla.edu/stat/r/dae/t_test_power.htm) 
- [FAQ - How is effect size used in power analysis?  UCLA: Statistical Consulting Group.](http://www.ats.ucla.edu/stat/mult_pkg/faq/general/effect_size_power/effect_size_power.htm) 

